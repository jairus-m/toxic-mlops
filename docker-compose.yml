services:
  mlflow-server:
    image: python:3.11-slim
    ports:
      - "5000:5000"
    command: >
      sh -c "pip install mlflow psycopg2-binary &&
             mkdir -p /mlflow/artifacts &&
             chmod -R 777 /mlflow &&
             mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow/mlflow.db --artifacts-destination /mlflow/artifacts --serve-artifacts"
    volumes:
      - ./assets/mlflow:/mlflow
    environment:
      - APP_ENV=development

  trainer:
    build:
      context: .
      dockerfile: ./src/sklearn_training/Dockerfile
    volumes:
      - ./assets:/app/assets
    environment:
      - APP_ENV=development
      - TRAIN_MODEL=${TRAIN_MODEL:-true}
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    depends_on:
      mlflow-server:
        condition: service_started

  backend:
    build:
      context: .
      dockerfile: ./src/fastapi_backend/Dockerfile
    volumes:
      - ./assets:/app/assets
    ports:
      - "8000:8000"
    environment:
      - APP_ENV=development
    depends_on:
      trainer:
        condition: service_completed_successfully

  frontend:
    build:
      context: .
      dockerfile: ./src/streamlit_frontend/Dockerfile
    ports:
      - "8501:8501"
    volumes:
      - ./assets:/app/assets
    environment:
      - APP_ENV=development
      - FASTAPI_BACKEND_URL=http://backend:8000
    depends_on:
      backend:
        condition: service_started
  
  monitoring:
    build:
      context: .
      dockerfile: ./src/streamlit_monitoring/Dockerfile
    ports:
      - "8502:8502"
    volumes:
      - ./assets:/app/assets
    environment:
      - APP_ENV=development
      - FASTAPI_BACKEND_URL=http://backend:8000
    depends_on:
      backend:
        condition: service_started
